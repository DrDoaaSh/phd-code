{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DrDoaaSh/phd-code/blob/main/comparModels_CNN%2BLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H5P967qvonHC",
        "outputId": "48d455a3-d578-4873-e2d5-ca63b6b44f18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83r4FrFXonHD"
      },
      "source": [
        "## Libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xDBzIvShonHD"
      },
      "outputs": [],
      "source": [
        "from scipy import misc, ndimage, signal\n",
        "from sklearn.model_selection  import train_test_split\n",
        "import numpy\n",
        "import numpy as np\n",
        "import random\n",
        "import ntpath\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from keras import backend as K\n",
        "from time import time\n",
        "import time as tm\n",
        "import datetime\n",
        "from operator import itemgetter\n",
        "import glob\n",
        "from skimage.util.shape import view_as_blocks\n",
        "from keras.utils import np_utils\n",
        "from keras.utils import to_categorical\n",
        "\n",
        "\n",
        "import numpy\n",
        "import numpy as np\n",
        "import random\n",
        "import os\n",
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.colors as colors\n",
        "from keras.layers import Activation\n",
        "import tensorflow as tf\n",
        "import cv2\n",
        "from tensorflow.keras.layers import Lambda, Layer, ReLU\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, LSTM, SpatialDropout2D, Concatenate\n",
        "tf.keras.layers.Concatenate()\n",
        "from tensorflow.keras.layers import Conv2D,ConvLSTM2D, MaxPooling2D, AveragePooling2D, AveragePooling3D,GlobalAveragePooling3D, GlobalAveragePooling2D, GlobalAveragePooling1D, UpSampling2D, BatchNormalization\n",
        "from keras.layers.core import Reshape\n",
        "from keras import optimizers\n",
        "from tensorflow.keras import regularizers\n",
        "from keras import Input, Model\n",
        "from time import time\n",
        "import time as tm\n",
        "from keras.initializers import Constant, RandomNormal, glorot_normal\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from keras import backend as K\n",
        "from tensorflow.keras.utils import plot_model\n",
        "from keras.layers import  concatenate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jGYyQp73onHE"
      },
      "source": [
        "## 30 SRM filters for preprocessing and the activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ou4cMP4TonHE",
        "outputId": "26d017af-ed5b-4362-baae-931966cf2d28"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5, 5, 1, 30)\n"
          ]
        }
      ],
      "source": [
        "################################################## 30 SRM FILTERS\n",
        "srm_weights = np.load('/content/drive/MyDrive/Colab Notebooks/SRM_Kernels.npy')\n",
        "\n",
        "biasSRM=numpy.ones(30)\n",
        "print (srm_weights.shape)\n",
        "################################################## TLU ACTIVATION FUNCTION\n",
        "\n",
        "T3 = 3\n",
        "def TLU3(x):\n",
        "    tlu3 = K.tanh(x)*T3\n",
        "    return tlu3\n",
        "\n",
        "\n",
        "T2 = 2\n",
        "def TLU2(x):\n",
        "    tlu2 = K.tanh(x)*T2\n",
        "    return tlu2\n",
        "\n",
        "\n",
        "def Tanh3(x):\n",
        "    tlu3 = K.tanh(x)*T3\n",
        "    return tlu3\n",
        "###########################################################################\n",
        "\n",
        "def thtanh(x,t):\n",
        "    th=K.tanh(x)*t\n",
        "    return th\n",
        "\n",
        "\n",
        "\n",
        "from keras.layers import Layer\n",
        "class Thtanh(Layer):\n",
        "\n",
        "    def __init__(self, th=1.0, trainable=False, **kwargs):\n",
        "        super(Thtanh, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.th = th\n",
        "        self.trainable = trainable\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.th_factor = K.variable(self.th,\n",
        "                                      dtype=K.floatx(),\n",
        "                                      name='th_factor')\n",
        "\n",
        "        if self.trainable:\n",
        "            self._trainable_weights.append(self.th_factor)\n",
        "\n",
        "        super(Thtanh, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        return thtanh(inputs, self.th_factor)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'th': self.get_weights()[0] if self.trainable else self.th,\n",
        "                  'trainable': self.trainable}\n",
        "        base_config = super(Thtanh, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape\n",
        "\n",
        "############################################################################\n",
        "\n",
        "def tlu(x,t):\n",
        "    tlu = tf.maximum(tf.minimum(x, t), -t)\n",
        "    return tlu\n",
        "\n",
        "#from keras.utils.generic_utils import get_custom_objects\n",
        "#get_custom_objects().update({'tlu': Activation(tlu)})\n",
        "\n",
        "from keras.layers import Layer\n",
        "class TLU(Layer):\n",
        "\n",
        "    def __init__(self, th=1.0, trainable=False, **kwargs):\n",
        "        super(TLU, self).__init__(**kwargs)\n",
        "        self.supports_masking = True\n",
        "        self.th = th\n",
        "        self.trainable = trainable\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        self.th_factor = K.variable(self.th,\n",
        "                                      dtype=K.floatx(),\n",
        "                                      name='th_factor')\n",
        "\n",
        "        if self.trainable:\n",
        "            self._trainable_weights.append(self.th_factor)\n",
        "\n",
        "        super(TLU, self).build(input_shape)\n",
        "\n",
        "    def call(self, inputs, mask=None):\n",
        "        return tlu(inputs, self.th_factor)\n",
        "\n",
        "    def get_config(self):\n",
        "        config = {'th': self.get_weights()[0] if self.trainable else self.th,\n",
        "                  'trainable': self.trainable}\n",
        "        base_config = super(TLU, self).get_config()\n",
        "        return dict(list(base_config.items()) + list(config.items()))\n",
        "\n",
        "    def compute_output_shape(self, input_shape):\n",
        "        return input_shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TfSPv7CkonHG"
      },
      "source": [
        "## TPU"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ravuvRcsonHG",
        "outputId": "21d47f63-c042-47df-a590-15bc4be58b41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab only includes TensorFlow 2.x; %tensorflow_version has no effect.\n",
            "Tensorflow version 2.12.0\n",
            "Running on TPU  ['10.74.228.114:8470']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:TPU system grpc://10.74.228.114:8470 has already been initialized. Reinitializing the TPU can cause previously created variables on TPU to be lost.\n"
          ]
        }
      ],
      "source": [
        "#https://www.tensorflow.org/guide/tpu\n",
        "#https://colab.research.google.com/github/tensorflow/docs/blob/master/site/en/guide/tpu.ipynb\n",
        "#https://colab.research.google.com/notebooks/tpu.ipynb#scrollTo=_pQCOmISAQBu\n",
        "\n",
        "%tensorflow_version 2.x\n",
        "import tensorflow as tf\n",
        "print(\"Tensorflow version \" + tf.__version__)\n",
        "\n",
        "try:\n",
        "  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n",
        "  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\n",
        "except ValueError:\n",
        "  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n",
        "\n",
        "tf.config.experimental_connect_to_cluster(tpu)\n",
        "tf.tpu.experimental.initialize_tpu_system(tpu)\n",
        "tpu_strategy = tf.distribute.TPUStrategy(tpu)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## yedroudj_Net"
      ],
      "metadata": {
        "id": "FoopVm6YplcX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Orginal Code :Strategy to improve the accuracy of convolutional neural network architectures applied to digital image steganalysis in the spatial domain\n",
        "## https://github.com/BioAITeam/Strategy-to-improve-CNN-applied-to-digital-image-steganalysis-in-the-spatial-domain\n",
        "\n",
        "def yedroudj_Net():\n",
        "\n",
        "    img_size= 256\n",
        "    print (\"using\",2,\"classes\")\n",
        "\n",
        "\n",
        "\n",
        "    # Preprocessing\n",
        "    inputs = Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
        "    layers = Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1),padding=\"same\", trainable=False, use_bias=True)(inputs)\n",
        "    layers = Thtanh(th=3.0, trainable=False)(layers)\n",
        "\n",
        "\n",
        "    # Block 1\n",
        "\n",
        "    #Layer 0\n",
        "    layers = Conv2D(30, (5,5), strides=(1,1),padding=\"same\", kernel_initializer='glorot_normal', kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=True, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = Concatenate()([layers, layers, layers])\n",
        "\n",
        "    # Block 2\n",
        "\n",
        "    #Layer 1\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(30, (5,5), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=True, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = AveragePooling2D((5,5), strides= 2, padding='same')(layers)\n",
        "\n",
        "    # Block 3\n",
        "\n",
        "    #Layer 2\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(32, (3,3), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = AveragePooling2D((5,5), strides= 2,padding=\"same\")(layers)\n",
        "\n",
        "    # Block 4\n",
        "    #Layer 3\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(64, (3,3), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = AveragePooling2D((5,5), strides=2,padding=\"same\")(layers)\n",
        "    # Block 5\n",
        "    #Layer 4\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(128, (3,3), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = Concatenate()([layers, layers, layers])\n",
        "    layers = GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
        "\n",
        "    # Block 6\n",
        "    #Layer 5, FC, Softmax\n",
        "\n",
        "    # FC\n",
        "    layers = Dense(128,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = Dense(64,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = Dense(32,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "\n",
        "    # Softmax\n",
        "    predictions = Dense(2, activation=\"softmax\", name=\"output_1\",kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    model = Model(inputs = inputs, outputs=predictions)\n",
        "    # Compile\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.95)#lrate\n",
        "\n",
        "    if compile:\n",
        "        model.compile(optimizer= optimizer,\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "        print (\"Yedroud-net model generated\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "eGSSc9ZTNvS6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "##  yedroudj_Net with LSTM classifier\n",
        "\n",
        "def yedroudj_Net( ):\n",
        "\n",
        "\n",
        "    img_size= 256\n",
        "    print (\"using\",2,\"classes\")\n",
        "\n",
        "\n",
        "\n",
        "    # Preprocessing\n",
        "    inputs = Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
        "    layers = Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1),padding=\"same\", trainable=False, use_bias=True)(inputs)\n",
        "    layers = Thtanh(th=3.0, trainable=False)(layers)\n",
        "\n",
        "\n",
        "    # Block 1\n",
        "\n",
        "    #Layer 0\n",
        "    layers = Conv2D(30, (5,5), strides=(1,1),padding=\"same\", kernel_initializer='glorot_normal', kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=True, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = Concatenate()([layers, layers, layers])\n",
        "\n",
        "    # Block 2\n",
        "\n",
        "    #Layer 1\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(30, (5,5), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=True, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = AveragePooling2D((5,5), strides= 2, padding='same')(layers)\n",
        "\n",
        "    # Block 3\n",
        "\n",
        "    #Layer 2\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(32, (3,3), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = AveragePooling2D((5,5), strides= 2,padding=\"same\")(layers)\n",
        "\n",
        "    # Block 4\n",
        "    #Layer 3\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(64, (3,3), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = AveragePooling2D((5,5), strides=2,padding=\"same\")(layers)\n",
        "    # Block 5\n",
        "    #Layer 4\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(128, (3,3), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = Concatenate()([layers, layers, layers])\n",
        "\n",
        "    layers = tf.keras.layers.AveragePooling2D((5,5), strides= (2,2))(layers)\n",
        "\n",
        "    layers = Reshape((14*14,384))(layers)\n",
        "\n",
        "    # LSTM\n",
        "    layers = LSTM(128,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001),return_sequences=True, trainable=False)(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = LSTM(64,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001),return_sequences=True, trainable=False)(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = LSTM(32,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001),return_sequences=True, trainable=False)(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "\n",
        "    #layers = GlobalAveragePooling1D(data_format=\"channels_last\")(layers)\n",
        "    layers = Flatten(name=\"flatten\")(layers)\n",
        "\n",
        "    # Softmax\n",
        "    predictions = Dense(2, activation=\"softmax\", name=\"output_1\",kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    model = Model(inputs = inputs, outputs=predictions)\n",
        "    # Compile\n",
        "    #optimizer = tf.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
        "    #optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.95)#lrate\n",
        "    optimizer= tf.optimizers.Adam(lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "\n",
        "    if compile:\n",
        "        model.compile(optimizer= optimizer,\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "        print (\"Yedroud-net model generated\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "L7e2O4DrsM_2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Ye_Net"
      ],
      "metadata": {
        "id": "5IVvyv0NprUq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Orginal Code : Strategy to improve the accuracy of convolutional neural network architectures applied to digital image steganalysis in the spatial domain\n",
        "## https://github.com/BioAITeam/Strategy-to-improve-CNN-applied-to-digital-image-steganalysis-in-the-spatial-domain\n",
        "def Ye_Net():\n",
        "\n",
        "    img_size=256\n",
        "    #Inputs\n",
        "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
        "    print(inputs.shape)\n",
        "\n",
        "    #Block 1\n",
        "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=Tanh3, use_bias=True)(inputs)\n",
        "    #layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    #layer1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    print(layers.shape)\n",
        "\n",
        "    #Block 2\n",
        "\n",
        "    #layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "\n",
        "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = tf.keras.layers.Concatenate()([layers, layers, layers])\n",
        "    print(layers.shape)\n",
        "\n",
        "    #Block 3\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    print(layers.shape)\n",
        "\n",
        "    #Block 4\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
        "    print(layers.shape)\n",
        "\n",
        "    #Block 5\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    print(layers.shape)\n",
        "\n",
        "    #Block 6\n",
        "    layers = tf.keras.layers.Concatenate()([layers, layers, layers])\n",
        "    layers = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
        "\n",
        "    layers = tf.keras.layers.Dense(128,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    #layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense(64,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    #layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense(32,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    predictions = tf.keras.layers.Dense(2,kernel_initializer='glorot_normal', activation=\"softmax\", name=\"output_1\",kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    print(predictions.shape)\n",
        "\n",
        "    #Model generation\n",
        "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
        "    #Optimizer\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.95)#lrate\n",
        "    #Compilator\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print (\"Ye-net model 2 generated\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "Do5sf5rFssB4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SznXx_ZW_rD4"
      },
      "outputs": [],
      "source": [
        "##Ye_Net with LSTM\n",
        "def Ye_Net():\n",
        "\n",
        "    img_size=256\n",
        "    #Inputs\n",
        "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
        "\n",
        "\n",
        "    #Block 1\n",
        "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=Tanh3, use_bias=True)(inputs)\n",
        "\n",
        "\n",
        "\n",
        "    #Block 2\n",
        "\n",
        "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = tf.keras.layers.Concatenate()([layers, layers, layers])\n",
        "\n",
        "\n",
        "    #Block 3\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "\n",
        "\n",
        "    #Block 4\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = tf.keras.layers.Conv2D(30, (3,3), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = tf.keras.layers.AveragePooling2D((2,2), strides= (2,2))(layers)\n",
        "\n",
        "\n",
        "    #Block 5\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = tf.keras.layers.Conv2D(32, (5,5), strides=(1,1), kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "\n",
        "\n",
        "    #Block 6\n",
        "    layers = tf.keras.layers.Concatenate()([layers, layers, layers])\n",
        "\n",
        "    layers = tf.keras.layers.AveragePooling2D((5,5), strides= (2,2))(layers)\n",
        "\n",
        "    layers = Reshape((58*58,96))(layers)\n",
        "    # LSTM\n",
        "    layers = LSTM(32,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001),return_sequences=True, trainable=False)(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = LSTM(16,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001),return_sequences=True, trainable=False)(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = LSTM(8,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001),return_sequences=True, trainable=False)(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "\n",
        "    #layers = GlobalAveragePooling1D(data_format=\"channels_last\")(layers)\n",
        "    layers = Flatten(name=\"flatten\")(layers)\n",
        "\n",
        "\n",
        "\n",
        "    predictions = tf.keras.layers.Dense(2,kernel_initializer='glorot_normal', activation=\"softmax\", name=\"output_1\",kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "\n",
        "\n",
        "    #Model generation\n",
        "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
        "    #Optimizer\n",
        "    optimizer= tf.keras.optimizers.legacy.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "    #Compilator\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "    print (\"Ye-net model 2 generated\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Xu_Net"
      ],
      "metadata": {
        "id": "ukNFndcRpvgM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##Orginal Code :Strategy to improve the accuracy of convolutional neural network architectures applied to digital image steganalysis in the spatial domain\n",
        "## https://github.com/BioAITeam/Strategy-to-improve-CNN-applied-to-digital-image-steganalysis-in-the-spatial-domain\n",
        "def Xu_Net():\n",
        "\n",
        "    img_size= 256\n",
        "\n",
        "    #tf.reset_default_graph()\n",
        "\n",
        "    print (\"using\",2,\"classes\")\n",
        "\n",
        "    #Preprocessing\n",
        "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
        "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=Tanh3, use_bias=True)(inputs)\n",
        "\n",
        "\n",
        "\n",
        "    #Block 1\n",
        "\n",
        "    #Layer 0\n",
        "    layers = Conv2D(8, (5,5), strides=(1,1),padding=\"same\", kernel_initializer='glorot_normal', kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=True, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = Concatenate()([layers, layers, layers])\n",
        "\n",
        "    #Block 2\n",
        "\n",
        "    #Layer 1\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(16, (5,5), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=True, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = AveragePooling2D((5,5), strides= 2, padding='same')(layers)\n",
        "\n",
        "    #Block 3\n",
        "\n",
        "    #Layer 2\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(32, (1,1), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = AveragePooling2D((5,5), strides= 2,padding=\"same\")(layers)\n",
        "\n",
        "    #Block 4\n",
        "    #Layer 3\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(64, (1,1), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = AveragePooling2D((5,5), strides=2,padding=\"same\")(layers)\n",
        "    #Block 5\n",
        "    #Layer 4\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(128, (1,1), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = Concatenate()([layers, layers, layers])\n",
        "    layers = GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
        "\n",
        "    #Block 6\n",
        "    #Layer 5, FC, Softmax\n",
        "\n",
        "    #FC\n",
        "    layers = Dense(128,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = Dense(64,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = Dense(32,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "\n",
        "    #Softmax\n",
        "    predictions = Dense(2, activation=\"softmax\", name=\"output_1\",kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    model =tf.keras.Model(inputs = inputs, outputs=predictions)\n",
        "    #Compile\n",
        "    optimizer = tf.keras.optimizers.SGD(learning_rate=0.005, momentum=0.95)\n",
        "\n",
        "    if compile:\n",
        "        model.compile(optimizer= optimizer,\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "        print (\"Xunet\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "kLjgxbRJs50R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8P2M1dO35ZKa"
      },
      "outputs": [],
      "source": [
        "##Xu_Net with LSTM\n",
        "def Xu_Net( ):\n",
        "\n",
        "    #tf.reset_default_graph()\n",
        "    #tf.keras.backend.clear_session()\n",
        "    print (\"using\",2,\"classes\")\n",
        "\n",
        "    img_size=256\n",
        "\n",
        "    #Preprocessing\n",
        "    inputs = tf.keras.Input(shape=(img_size,img_size,1), name=\"input_1\")\n",
        "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=Tanh3, use_bias=True)(inputs)\n",
        "\n",
        "\n",
        "\n",
        "    #Block 1\n",
        "\n",
        "    #Layer 0\n",
        "    layers = Conv2D(8, (5,5), strides=(1,1),padding=\"same\", kernel_initializer='glorot_normal', kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=True, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = Concatenate()([layers, layers, layers])\n",
        "\n",
        "    #Block 2\n",
        "\n",
        "    #Layer 1\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(16, (5,5), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=True, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = AveragePooling2D((5,5), strides= 2, padding='same')(layers)\n",
        "\n",
        "    #Block 3\n",
        "\n",
        "    #Layer 2\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(32, (1,1), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = AveragePooling2D((5,5), strides= 2,padding=\"same\")(layers)\n",
        "\n",
        "    #Block 4\n",
        "    #Layer 3\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(64, (1,1), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = AveragePooling2D((5,5), strides=2,padding=\"same\")(layers)\n",
        "    #Block 5\n",
        "    #Layer 4\n",
        "    layers = tf.keras.layers.SpatialDropout2D(rate=0.1)(layers)\n",
        "    layers = Conv2D(128, (1,1), strides=1,padding=\"same\", kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = Concatenate()([layers, layers, layers])\n",
        "\n",
        "    layers = AveragePooling2D((5,5), strides=2,padding=\"same\")(layers)\n",
        "\n",
        "    # Block 6\n",
        "    #Layer 5, LSTM , Softmax\n",
        "    layers = Reshape((16*16,384))(layers)\n",
        "    # LSTM\n",
        "    layers = LSTM(128,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001),return_sequences=True, trainable=False)(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = LSTM(64,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001),return_sequences=True, trainable=False)(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = LSTM(32,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001),return_sequences=True, trainable=False)(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "\n",
        "    layers = Flatten(name=\"flatten\")(layers)\n",
        "\n",
        "    #Softmax\n",
        "    predictions = Dense(2, activation=\"softmax\", name=\"output_1\",kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001))(layers)\n",
        "    model =tf.keras.Model(inputs = inputs, outputs=predictions)\n",
        "    #Compile\n",
        "\n",
        "    optimizer= tf.keras.optimizers.legacy.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "    if compile:\n",
        "        model.compile(optimizer= optimizer,\n",
        "                      loss='binary_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "        print (\"Xunet\")\n",
        "    return model\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Zhu_Net"
      ],
      "metadata": {
        "id": "QfPZXonCp0lg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "###Orginal Code: Sensitivity of deep learning applied to spatial image steganalysis\n",
        "### https://github.com/BioAITeam/Sensitivity-of-deep-learning-applied-to-Spatial-Image-Steganalysis\n",
        "def Zhu_Net():\n",
        "\n",
        "    img_size=256\n",
        "    #Inputs\n",
        "    inputs = tf.keras.Input(shape=(img_size,img_size,1),name=\"input_1\")\n",
        "\n",
        "    #Layer 1\n",
        "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=Tanh3, use_bias=True)(inputs)\n",
        "    layer1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "\n",
        "    #Layer 2\n",
        "    layer1 = tf.keras.layers.SpatialDropout2D(rate=0.1)(layer1)\n",
        "    layer23 = tf.keras.layers.SeparableConv2D(30,(3,3),activation=\"relu\",depth_multiplier=3,padding=\"same\")(layer1)\n",
        "    layer23 = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer23)\n",
        "    layer23 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer23)\n",
        "\n",
        "    #Layer 3\n",
        "    layer23 = tf.keras.layers.SeparableConv2D(30,(3,3),activation=\"relu\",depth_multiplier=3,padding=\"same\")(layer23)\n",
        "    layer23 = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer23)\n",
        "    layer23 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer23)\n",
        "\n",
        "    #Shorcut\n",
        "    layers= tf.keras.layers.Add()([layer23, layer1])\n",
        "\n",
        "    #Layer 4\n",
        "    layers = tf.keras.layers.Conv2D(32, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal', padding='same')(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = tf.keras.layers.AveragePooling2D((5,5), strides= (2,2),padding=\"same\")(layers)\n",
        "\n",
        "    #Layer 5\n",
        "    layers = tf.keras.layers.Conv2D(32, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal',padding=\"same\")(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = tf.keras.layers.AveragePooling2D((5,5), strides= (2,2),padding=\"same\")(layers)\n",
        "\n",
        "    #Layer 6\n",
        "    layers = tf.keras.layers.Conv2D(64, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal',padding=\"same\")(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = tf.keras.layers.AveragePooling2D((5,5), strides= (2,2),padding=\"same\")(layers)\n",
        "\n",
        "    #Layer 7\n",
        "    layers = tf.keras.layers.Conv2D(128, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal',padding=\"same\")(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "\n",
        "    #Layer 8\n",
        "    layers = tf.keras.layers.GlobalAveragePooling2D(data_format=\"channels_last\")(layers)\n",
        "\n",
        "\n",
        "    #Layer 9, FC, Softmax\n",
        "    layers = tf.keras.layers.Dense(128,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense(64 ,activation=\"relu\")(layers)\n",
        "    layers = tf.keras.layers.Dropout(0.2)(layers)\n",
        "    layers = tf.keras.layers.Dense(32 ,activation=\"relu\")(layers)\n",
        "\n",
        "    #Softmax\n",
        "    predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\n",
        "\n",
        "    #Model generation\n",
        "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
        "\n",
        "    #Optimizer\n",
        "    optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9)\n",
        "\n",
        "    #Compilator\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    print (\"Zhu-net model generated\")\n",
        "    return model"
      ],
      "metadata": {
        "id": "BXA5pmPLtOJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0qlpWoydhEKp"
      },
      "outputs": [],
      "source": [
        "## sensetive + LSTM\n",
        "def Zhu_Net():\n",
        "    print (\"using\",2,\"classes\")\n",
        "\n",
        "    img_size=256\n",
        "    #Inputs\n",
        "    inputs = tf.keras.Input(shape=(img_size,img_size,1),name=\"input_1\")\n",
        "\n",
        "    #Layer 1\n",
        "    layers = tf.keras.layers.Conv2D(30, (5,5), weights=[srm_weights,biasSRM], strides=(1,1), trainable=False, activation=Tanh3, use_bias=True)(inputs)\n",
        "    layer1 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "\n",
        "    #Layer 2\n",
        "    layer1 = tf.keras.layers.SpatialDropout2D(rate=0.1)(layer1)\n",
        "    layer23 = tf.keras.layers.SeparableConv2D(30,(3,3),activation=\"relu\",depth_multiplier=3,padding=\"same\")(layer1)\n",
        "    layer23 = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer23)\n",
        "    layer23 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer23)\n",
        "\n",
        "    #Layer 3\n",
        "    layer23 = tf.keras.layers.SeparableConv2D(30,(3,3),activation=\"relu\",depth_multiplier=3,padding=\"same\")(layer23)\n",
        "    layer23 = tf.keras.layers.Lambda(tf.keras.backend.abs)(layer23)\n",
        "    layer23 = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layer23)\n",
        "\n",
        "    #Shorcut\n",
        "    layers= tf.keras.layers.Add()([layer23, layer1])\n",
        "\n",
        "    #Layer 4\n",
        "    layers = tf.keras.layers.Conv2D(32, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal', padding='same')(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = tf.keras.layers.AveragePooling2D((5,5), strides= (2,2),padding=\"same\")(layers)\n",
        "\n",
        "    #Layer 5\n",
        "    layers = tf.keras.layers.Conv2D(32, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal',padding=\"same\")(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = tf.keras.layers.AveragePooling2D((5,5), strides= (2,2),padding=\"same\")(layers)\n",
        "\n",
        "    #Layer 6\n",
        "    layers = tf.keras.layers.Conv2D(64, (3,3), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal',padding=\"same\")(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "    layers = tf.keras.layers.AveragePooling2D((5,5), strides= (2,2),padding=\"same\")(layers)\n",
        "\n",
        "    #Layer 7\n",
        "    layers = tf.keras.layers.Conv2D(128, (5,5), strides=(1,1), activation=\"relu\", kernel_initializer='glorot_normal',padding=\"same\")(layers)\n",
        "    layers = tf.keras.layers.Lambda(tf.keras.backend.abs)(layers)\n",
        "    layers = tf.keras.layers.BatchNormalization(momentum=0.2, epsilon=0.001, center=True, scale=False, trainable=True, fused=None, renorm=False, renorm_clipping=None, renorm_momentum=0.4, adjustment=None)(layers)\n",
        "\n",
        "    #Layer 8\n",
        "\n",
        "    layers = tf.keras.layers.AveragePooling2D((5,5), strides= (2,2),padding=\"same\")(layers)\n",
        "\n",
        "\n",
        "    layers = Reshape((16*16,128))(layers)\n",
        "    # FC\n",
        "    layers = LSTM(128,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001),return_sequences=True, trainable=False)(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = LSTM(64,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001),return_sequences=True, trainable=False)(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "    layers = LSTM(32,kernel_initializer='glorot_normal',kernel_regularizer=tf.keras.regularizers.l2(0.0001),bias_regularizer=tf.keras.regularizers.l2(0.0001),return_sequences=True, trainable=False)(layers)\n",
        "    layers = ReLU(negative_slope=0.1, threshold=0)(layers)\n",
        "\n",
        "    layers = Flatten(name=\"flatten\")(layers)\n",
        "\n",
        "    #Softmax\n",
        "    predictions = tf.keras.layers.Dense(2, activation=\"softmax\", name=\"output_1\")(layers)\n",
        "\n",
        "    #Model generation\n",
        "    model = tf.keras.Model(inputs = inputs, outputs=predictions)\n",
        "\n",
        "    #Optimizer\n",
        "    optimizer= tf.keras.optimizers.legacy.Adam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
        "\n",
        "    #Compilator\n",
        "    model.compile(optimizer=optimizer, loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    print (\"Zhu-net model generated\")\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F73TYdW0onHI"
      },
      "source": [
        "## Defining different functions to work with the architecture"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C2mKq_nKonHJ"
      },
      "outputs": [],
      "source": [
        "\n",
        "def Final_Results_Valid(PATH_trained_models):\n",
        "    global AccValid\n",
        "    global LossValid\n",
        "    AccValid = []\n",
        "    LossValid = []\n",
        "    B_accuracy = 0 #B --> Best\n",
        "    for filename in sorted(os.listdir(PATH_trained_models)):\n",
        "        if filename != ('train') and filename != ('validation'):\n",
        "            print(filename)\n",
        "            with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "                 _model = yedroudj_Net()\n",
        "            _model.load_weights(PATH_trained_models+'/'+filename)\n",
        "            loss,accuracy = _model.evaluate(X_valid, y_valid, verbose=0)\n",
        "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}'+'\\n')\n",
        "\n",
        "            BandAccValid  = accuracy\n",
        "            BandLossValid = loss\n",
        "            AccValid.append(BandAccValid)\n",
        "            LossValid.append(BandLossValid)\n",
        "\n",
        "            if accuracy > B_accuracy:\n",
        "                B_accuracy = accuracy\n",
        "                B_loss = loss\n",
        "                B_name = filename\n",
        "\n",
        "    print(\"\\n\\nBest\")\n",
        "    print(B_name)\n",
        "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "id_VFPeJonHJ"
      },
      "outputs": [],
      "source": [
        "def Final_Results_Train(PATH_trained_models):\n",
        "    global AccTrain\n",
        "    global LossTrain\n",
        "    AccTrain = []\n",
        "    LossTrain = []\n",
        "    B_accuracy = 0 #B --> Best\n",
        "    for filename in sorted(os.listdir(PATH_trained_models)):\n",
        "        if filename != ('train') and filename != ('validation'):\n",
        "            print(filename)\n",
        "            with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "                 _model = yedroudj_Net()\n",
        "            _model.load_weights(PATH_trained_models+'/'+filename)\n",
        "            loss,accuracy = _model.evaluate(X_train, y_train, verbose=0)\n",
        "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}'+'\\n')\n",
        "\n",
        "            BandAccTrain  = accuracy\n",
        "            BandLossTrain = loss\n",
        "            AccTrain.append(BandAccTrain)\n",
        "            LossTrain.append(BandLossTrain)\n",
        "\n",
        "            if accuracy > B_accuracy:\n",
        "                B_accuracy = accuracy\n",
        "                B_loss = loss\n",
        "                B_name = filename\n",
        "\n",
        "    print(\"\\n\\nBest\")\n",
        "    print(B_name)\n",
        "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lcEAnHqhonHJ"
      },
      "outputs": [],
      "source": [
        "def Final_Results_Test(PATH_trained_models):\n",
        "    global AccTest\n",
        "    global LossTest\n",
        "    AccTest = []\n",
        "    LossTest= []\n",
        "    B_accuracy = 0 #B --> Best\n",
        "    for filename in sorted(os.listdir(PATH_trained_models)):\n",
        "        if filename != ('train') and filename != ('validation'):\n",
        "            print(filename)\n",
        "            with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "                 _model = yedroudj_Net()\n",
        "            _model.load_weights(PATH_trained_models+'/'+filename)\n",
        "            loss,accuracy = _model.evaluate(X_test, y_test, verbose=0)\n",
        "\n",
        "            print(f'Loss={loss:.4f} y Accuracy={accuracy:0.4f}'+'\\n')\n",
        "\n",
        "            BandAccTest  = accuracy\n",
        "            BandLossTest = loss\n",
        "            AccTest.append(BandAccTest)\n",
        "            LossTest.append(BandLossTest)\n",
        "\n",
        "            if accuracy > B_accuracy:\n",
        "                B_accuracy = accuracy\n",
        "                B_loss = loss\n",
        "                B_name = filename\n",
        "\n",
        "    print(\"\\n\\nBest\")\n",
        "    print(B_name)\n",
        "    print(f'Loss={B_loss:.4f} y Accuracy={B_accuracy:0.4f}'+'\\n')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hT_OafMmonHK"
      },
      "outputs": [],
      "source": [
        "def graphics(AccTest, AccTrain, AccValid, LossTest, LossTrain, LossValid, model_name, path_img_base):\n",
        "    if not os.path.exists(path_img_base+\"/\"+model_name):\n",
        "       os.makedirs(path_img_base+\"/\"+model_name)\n",
        "\n",
        "    with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "        model = DAMO_Net()\n",
        "\n",
        "    lossTEST,accuracyTEST   = model.evaluate(X_test, y_test,verbose=None)\n",
        "    lossTRAIN,accuracyTRAIN = model.evaluate(X_train, y_train,verbose=None)\n",
        "    lossVALID,accuracyVALID = model.evaluate(X_valid, y_valid,verbose=None)\n",
        "\n",
        "    with plt.style.context('seaborn-white'):\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.plot(np.concatenate([np.array([accuracyTRAIN]),np.array(AccTrain)],axis=0))\n",
        "        plt.plot(np.concatenate([np.array([accuracyVALID]),np.array(AccValid)],axis=0))\n",
        "        plt.plot(np.concatenate([np.array([accuracyTEST]),np.array(AccTest)],axis=0)) #Test\n",
        "        plt.title('Accuracy Vs Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation', 'Test'], loc='upper left')\n",
        "        plt.grid('on')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Accuracy_yedroudj_Net_'+model_name+'.eps', format='eps')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Accuracy_yedroudj_Net_'+model_name+'.svg', format='svg')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Accuracy_yedroudj_Net_'+model_name+'.pdf', format='pdf')\n",
        "        plt.show()\n",
        "\n",
        "        plt.figure(figsize=(10, 10))\n",
        "        plt.plot(np.concatenate([np.array([lossTRAIN]),np.array(LossTrain)],axis=0))\n",
        "        plt.plot(np.concatenate([np.array([lossVALID]),np.array(LossValid)],axis=0))\n",
        "        plt.plot(np.concatenate([np.array([lossTEST]),np.array(LossTest)],axis=0)) #Test\n",
        "        plt.title('Loss Vs Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.legend(['Train', 'Validation', 'Test'], loc='upper left')\n",
        "        plt.grid('on')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Loss_yedroudj_Net'+model_name+'.eps', format='eps')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Loss_yedroudj_Net'+model_name+'.svg', format='svg')\n",
        "        plt.savefig(path_img_base+'/'+model_name+'/Loss_yedroudj_Net'+model_name+'.pdf', format='pdf')\n",
        "        plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z3Fixnm89RZe"
      },
      "source": [
        "### **ROC**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aeM-7w4Y9THv"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import (\n",
        "    average_precision_score,\n",
        "    precision_recall_curve,\n",
        "    roc_auc_score,\n",
        "    roc_curve,\n",
        ")\n",
        "\n",
        "def get_curve(gt, pred, target_names,model_name):\n",
        "    labels=[]\n",
        "    for i in range(len(target_names)):\n",
        "\n",
        "        curve_function = roc_curve\n",
        "        auc_roc = roc_auc_score(gt[:, i], pred[:, i])\n",
        "        label = model_name+target_names[i] + \" AUC: %.3f \" % auc_roc\n",
        "        labels.append(label)\n",
        "        xlabel = \"False positive rate\"\n",
        "        ylabel = \"True positive rate\"\n",
        "        a, b, _ = curve_function(gt[:, i], pred[:, i])\n",
        "        plt.figure(1, figsize=(7, 7))\n",
        "        plt.plot([0, 1], [0, 1], 'k--')\n",
        "        plt.plot(a, b, label=label)\n",
        "        plt.xlabel(xlabel)\n",
        "        plt.ylabel(ylabel)\n",
        "\n",
        "        plt.legend(loc='upper center', bbox_to_anchor=(1.3, 1),\n",
        "                  fancybox=True, ncol=1)\n",
        "\n",
        "    return [a,b],labels\n",
        "labels = [\"Cover\",\"Stego\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "w491BfrOonHK"
      },
      "outputs": [],
      "source": [
        "def top_models(AccTest,AccTrain,AccValid):\n",
        "    numbers=AccTest\n",
        "    numbers_sort = sorted(enumerate(numbers), key=itemgetter(1),  reverse=True)\n",
        "    for i in range(int(len(numbers)*(0.05))): #5% total epochs\n",
        "        index, value = numbers_sort[i]\n",
        "        print(\"Test Accuracy {}, epoch:{}\\n\".format(value, index+1))\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "    numbers=AccTrain\n",
        "    numbers_sort = sorted(enumerate(numbers), key=itemgetter(1),  reverse=True)\n",
        "    for i in range(int(len(numbers)*(0.05))): #5% total epochs\n",
        "        index, value = numbers_sort[i]\n",
        "        print(\"Train Accuracy {}, epoch:{}\\n\".format(value, index+1))\n",
        "\n",
        "    print(\"\")\n",
        "\n",
        "    numbers=AccValid\n",
        "    numbers_sort = sorted(enumerate(numbers), key=itemgetter(1),  reverse=True)\n",
        "    for i in range(int(len(numbers)*(0.05))): #5% total epochs\n",
        "        index, value = numbers_sort[i]\n",
        "        print(\"Validation Accuracy {}, epoch:{}\\n\".format(value, index+1))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gTts-1iqonHL"
      },
      "outputs": [],
      "source": [
        "def trainTPU(path_model, epochs, model_Name):\n",
        "    global model_name\n",
        "    start_time = tm.time()\n",
        "    model_name = model_Name\n",
        "    path_log_base = path_model+'/'+model_Name\n",
        "    if not os.path.exists(path_log_base):\n",
        "        os.makedirs(path_log_base)\n",
        "\n",
        "    with tpu_strategy.scope(): # creating the model in the TPUStrategy scope means we will train the model on the TPU\n",
        "         model = yedroudj_Net()\n",
        "         model.summary()\n",
        "\n",
        "\n",
        "\n",
        "    epoch_ = 1\n",
        "    for epoch in range(epochs):\n",
        "        epoch=epoch+1\n",
        "        print(\"epoch \",epoch)\n",
        "\n",
        "        model.fit(X_train,y_train,validation_data=(X_valid,y_valid), batch_size=64, epochs=epoch_, verbose=1)\n",
        "\n",
        "\n",
        "        model.save_weights(path_model+'/'+model_name+'/'+str(epoch).zfill(4)+'.hdf5', overwrite=True)\n",
        "\n",
        "    TIME = tm.time() - start_time\n",
        "    print(\"Time \"+model_name+\" = %s [seconds]\" % TIME)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ALASKA Dataset"
      ],
      "metadata": {
        "id": "ui4IMt5CGTOH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "#from stegano import lsb\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import scipy.spatial.distance as dist\n",
        "import string\n",
        "import random\n",
        "#from essential_generators import DocumentGenerator\n",
        "from scipy.fftpack import dct\n",
        "from skimage.io import imread\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "id": "90eMV2dKGVXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -r ~/.kaggle\n",
        "!mkdir ~/.kaggle\n",
        "!mv ./kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "6GT2o_qyHt4I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle competitions download -c alaska2-image-steganalysis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YIrdmRQJGvUo",
        "outputId": "be7dd63b-ef9c-4f24-c9a6-7b1b7feeef49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading alaska2-image-steganalysis.zip to /content\n",
            "100% 30.0G/30.0G [03:49<00:00, 209MB/s]\n",
            "100% 30.0G/30.0G [03:49<00:00, 140MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip -q /content/alaska2-image-steganalysis.zip -d /content/Dataset\n",
        "!rm /content/alaska2-image-steganalysis.zip"
      ],
      "metadata": {
        "id": "sGBdwE5WGyPT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# first approach: 6000 pairs for training, 1500 pairs for validation, and 7500 pairs were randomly chosen from the same trained set for testing.\n",
        "\n",
        "from pyasn1_modules.rfc2459 import X121Address\n",
        "cover_final_path=\"/content/Dataset/Cover\"\n",
        "stego_final_path=\"/content/Dataset/JUNIWARD\"\n",
        "cover_final_path_list=[]\n",
        "stego_final_path_list=[]\n",
        "pixel_cover=[]\n",
        "pixel_stego=[]\n",
        "\n",
        "\n",
        "def get_train_data(cover_final_path,stego_final_path):\n",
        "    train_df=pd.DataFrame()\n",
        "    train_df_2=pd.DataFrame()\n",
        "    for path in tqdm(os.listdir(cover_final_path)[:7500]):\n",
        "        cover_final_path_list.append(cover_final_path+\"/\"+path)\n",
        "        im = Image.open(cover_final_path+\"/\"+path)\n",
        "        im = im.convert('L')\n",
        "        im=im.resize((256,256))\n",
        "        im=np.array(im)\n",
        "        pixel_cover.append(im)\n",
        "    #train_df[\"Images\"]=cover_final_path_list\n",
        "    #train_df[\"Label\"]=0\n",
        "\n",
        "    for path in tqdm(os.listdir(stego_final_path)[:7500]):\n",
        "        stego_final_path_list.append(stego_final_path+\"/\"+path)\n",
        "        im = Image.open(stego_final_path+\"/\"+path)\n",
        "        im = im.convert('L')\n",
        "        im=im.resize((256,256))\n",
        "        im=np.array(im)\n",
        "        pixel_stego.append(im)\n",
        "    #train_df_2[\"Images\"]=stego_final_path_list\n",
        "    #train_df_2[\"Label\"]=1\n",
        "\n",
        "    #train_df=train_df.append(train_df_2)\n",
        "    return pixel_cover,pixel_stego\n",
        "\n",
        "pixel_cover,pixel_stego=get_train_data(cover_final_path,stego_final_path)\n",
        "\n",
        "\n",
        "#Y=train_df[\"Label\"].values\n",
        "pixel_cover=np.array(pixel_cover)\n",
        "pixel_stego=np.array(pixel_stego)\n",
        "X=np.concatenate([pixel_cover,pixel_stego])\n",
        "\n",
        "\n",
        "Y = (numpy.hstack(([0]*len(pixel_cover), [1]*len(pixel_stego))))\n",
        "Y = np_utils.to_categorical(Y, 2)\n",
        "\n",
        "X_dat0, X_dat1, y_dat0, y_dat1 = train_test_split(X,Y, test_size=0.50, random_state=64)\n",
        "X = np.concatenate([X_dat0,X_dat1],axis=0)\n",
        "Y = np.concatenate([y_dat0,y_dat1],axis=0)\n",
        "\n",
        "\n",
        "#Y = train_df[\"Label\"].values\n",
        "#X=X.reshape(15000,200,200,1)\n",
        "\n",
        "## 80,10,10\n",
        "#X_train = np.concatenate([X[0:6000],X[7500:13500]],axis=0)\n",
        "#X_valid = np.concatenate([X[6000:6750],X[13500:14250]],axis=0)\n",
        "#X_test  = np.concatenate([X[6750:7500],X[14250:15000]],axis=0)\n",
        "#y_train = np.concatenate([Y[0:6000],Y[7500:13500]],axis=0)\n",
        "#y_valid = np.concatenate([Y[6000:6750],Y[13500:14250]],axis=0)\n",
        "#y_test  = np.concatenate([Y[6750:7500],Y[14250:15000]],axis=0)\n",
        "\n",
        "## 40,10,50\n",
        "X_train = np.concatenate([X[0:6000],X[7500:13500]],axis=0)\n",
        "X_valid = np.concatenate([X[6000:7500],X[13500:15000]],axis=0)\n",
        "X_test  = np.concatenate([X[3750:7500],X[11250:15000]],axis=0)\n",
        "y_train = np.concatenate([Y[0:6000],Y[7500:13500]],axis=0)\n",
        "y_valid = np.concatenate([Y[6000:7500],Y[13500:15000]],axis=0)\n",
        "y_test  = np.concatenate([Y[3750:7500],Y[11250:15000]],axis=0)\n",
        "\n",
        "## 40,10,50\n",
        "#X_train = np.concatenate([X[0:3000],X[7500:10500]],axis=0)\n",
        "#X_valid = np.concatenate([X[3000:3750],X[10500:11250]],axis=0)\n",
        "#X_test  = np.concatenate([X[3750:7500],X[11250:15000]],axis=0)\n",
        "#y_train = np.concatenate([Y[0:3000],Y[7500:10500]],axis=0)\n",
        "#y_valid = np.concatenate([Y[3000:3750],Y[10500:11250]],axis=0)\n",
        "#y_test  = np.concatenate([Y[3750:7500],Y[11250:15000]],axis=0)\n",
        "\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "JaZE37heGWgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# creat one dataset and lables (X, Y)\n",
        "cover_final_path=\"/content/Dataset/Cover\"\n",
        "juniward_final_path=\"/content/Dataset/UERD\"\n",
        "\n",
        "cover_final_path_list=[]\n",
        "juniward_final_path=[]\n",
        "\n",
        "pixel_cover=[]\n",
        "pixel_juniward=[]\n",
        "\n",
        "\n",
        "\n",
        "def get_train_data(cover_final_path,juniward_final_path):\n",
        "    train_df=pd.DataFrame()\n",
        "    train_df_2=pd.DataFrame()\n",
        "    for path in tqdm(os.listdir(cover_final_path)[:7500]):\n",
        "        cover_final_path_list.append(cover_final_path+\"/\"+path)\n",
        "        im = Image.open(cover_final_path+\"/\"+path)\n",
        "        im = im.convert('L')\n",
        "        im=im.resize((200,200),1)\n",
        "        im=np.array(im)\n",
        "        pixel_cover.append(im)\n",
        "    train_df[\"Images\"]=cover_final_path_list\n",
        "    train_df[\"Label\"]=0\n",
        "\n",
        "    for path in tqdm(os.listdir(juniward_final_path)[:7500]):\n",
        "        juniward_final_path_list.append(juniward_final_path+\"/\"+path)\n",
        "        im = Image.open(juniward_final_path+\"/\"+path)\n",
        "        im = im.convert('L')\n",
        "        im=im.resize((200,200),1)\n",
        "        im=np.array(im)\n",
        "        pixel_juniward.append(im)\n",
        "    train_df_2[\"Images\"]=juniward_final_path_list\n",
        "    train_df_2[\"Label\"]=1\n",
        "\n",
        "    train_df=train_df.append(train_df_2)\n",
        "    return train_df,pixel_cover,pixel_juniward\n",
        "\n",
        "\n",
        "train_df,pixel_cover,pixel_juniward=get_train_data(cover_final_path,juniward_final_path)\n",
        "\n",
        "Y=train_df[\"Label\"].values\n",
        "pixel_cover=np.array(pixel_cover)\n",
        "pixel_juniward=np.array(pixel_juniward)\n",
        "X=np.concatenate([pixel_cover,pixel_juniward])\n",
        "X=X.reshape(15000,200,200,1)\n",
        "\n",
        "## 80,10,10\n",
        "#X_train = np.concatenate([X[0:6000],X[7500:13500]],axis=0)\n",
        "#X_valid = np.concatenate([X[6000:6750],X[13500:14250]],axis=0)\n",
        "#X_test  = np.concatenate([X[6750:7500],X[14250:15000]],axis=0)\n",
        "#y_train = np.concatenate([Y[0:6000],Y[7500:13500]],axis=0)\n",
        "#y_valid = np.concatenate([Y[6000:6750],Y[13500:14250]],axis=0)\n",
        "#y_test  = np.concatenate([Y[6750:7500],Y[14250:15000]],axis=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "9cGq6t8wFrYp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cover_final_path=\"/content/Dataset/Cover\"\n",
        "juniward_final_path=\"/content/Dataset/JUNIWARD\"\n",
        "\n",
        "cover_final_path_list=[]\n",
        "juniward_final_path_list=[]\n",
        "\n",
        "pixel_cover=[]\n",
        "pixel_juniward=[]\n",
        "\n",
        "\n",
        "\n",
        "def get_train_data(cover_final_path,juniward_final_path):\n",
        "    train_df=pd.DataFrame()\n",
        "    train_df_2=pd.DataFrame()\n",
        "    for path in tqdm(os.listdir(cover_final_path)[:7500]):\n",
        "        cover_final_path_list.append(cover_final_path+\"/\"+path)\n",
        "        im = Image.open(cover_final_path+\"/\"+path)\n",
        "        im = im.convert('L')\n",
        "        im=im.resize((200,200))\n",
        "        im=np.array(im)\n",
        "        pixel_cover.append(im)\n",
        "    train_df[\"Images\"]=cover_final_path_list\n",
        "    train_df[\"Label\"]=0\n",
        "\n",
        "    for path in tqdm(os.listdir(juniward_final_path)[:7500]):\n",
        "        juniward_final_path_list.append(juniward_final_path+\"/\"+path)\n",
        "        im = Image.open(juniward_final_path+\"/\"+path)\n",
        "        im = im.convert('L')\n",
        "        im=im.resize((200,200))\n",
        "        im=np.array(im)\n",
        "        pixel_juniward.append(im)\n",
        "    train_df_2[\"Images\"]=juniward_final_path_list\n",
        "    train_df_2[\"Label\"]=1\n",
        "\n",
        "    train_df=train_df.append(train_df_2)\n",
        "    return train_df,pixel_cover,pixel_juniward\n",
        "\n",
        "\n",
        "train_df,pixel_cover,pixel_juniward=get_train_data(cover_final_path,juniward_final_path)\n",
        "\n",
        "Y_test=train_df[\"Label\"].values\n",
        "pixel_cover=np.array(pixel_cover)\n",
        "pixel_juniward=np.array(pixel_juniward)\n",
        "X_test=np.concatenate([pixel_cover,pixel_juniward])\n",
        "X_test=X.reshape(15000,200,200)\n",
        "\n",
        "## 80,10,10\n",
        "#X_train = np.concatenate([X[0:6000],X[7500:13500]],axis=0)\n",
        "#X_valid = np.concatenate([X[6000:6750],X[13500:14250]],axis=0)\n",
        "#X_test  = np.concatenate([X[6750:7500],X[14250:15000]],axis=0)\n",
        "#y_train = np.concatenate([Y[0:6000],Y[7500:13500]],axis=0)\n",
        "#y_valid = np.concatenate([Y[6000:6750],Y[13500:14250]],axis=0)\n",
        "#y_test  = np.concatenate([Y[6750:7500],Y[14250:15000]],axis=0)\n",
        "\n"
      ],
      "metadata": {
        "id": "sg4tsJjIIGKm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train[15000],y_train[15000])"
      ],
      "metadata": {
        "id": "jkU-OwisFcWm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ALL ALASKA dataset (The three datasets\"jmipod+juniward+uerd)"
      ],
      "metadata": {
        "id": "lr5eaZeftMbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "GCS_DS_PATH = \"/content/Dataset\"\n",
        "def append_path(pre):\n",
        "    return np.vectorize(lambda file: os.path.join(GCS_DS_PATH, pre, file))\n",
        "\n",
        "sub = pd.read_csv('/content/Dataset/sample_submission.csv')\n",
        "train_filenames = np.array(os.listdir(\"/content/Dataset/Cover/\"))"
      ],
      "metadata": {
        "id": "l1UQa9z2OyvH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "np.random.seed(0)\n",
        "positives = train_filenames.copy()\n",
        "negatives = train_filenames.copy()\n",
        "np.random.shuffle(positives)\n",
        "np.random.shuffle(negatives)\n",
        "\n",
        "jmipod = append_path('/content/Dataset/JMiPOD')(positives[:7500])\n",
        "juniward = append_path('/content/Dataset/JUNIWARD')(positives[7500:15000])\n",
        "uerd = append_path('/content/Dataset/UERD')(positives[15000:22500])\n",
        "\n",
        "pos_paths = np.concatenate([jmipod, juniward, uerd])\n"
      ],
      "metadata": {
        "id": "OcCXpuqat6EL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pyasn1_modules.rfc2459 import X121Address\n",
        "cover_final_path=\"/content/Dataset/Cover\"\n",
        "stego_final_path =np.array(pos_paths)\n",
        "cover_final_path_list=[]\n",
        "stego_final_path_list=[]\n",
        "pixel_cover=[]\n",
        "pixel_stego=[]\n",
        "i=0\n",
        "\n",
        "def get_train_data(cover_final_path,stego_final_path):\n",
        "\n",
        "\n",
        "   for path in tqdm(os.listdir(cover_final_path)[:22500]):\n",
        "        cover_final_path_list.append(cover_final_path+\"/\"+path)\n",
        "        im = Image.open(cover_final_path+\"/\"+path)\n",
        "        im = im.convert('L')\n",
        "        im=im.resize((256,256))\n",
        "        im=np.array(im)\n",
        "        pixel_cover.append(im)\n",
        "\n",
        "\n",
        "\n",
        "   for i in range(0,len(stego_final_path)):\n",
        "\n",
        "     stego_final_path_list.append(stego_final_path)\n",
        "     im = Image.open(stego_final_path[i])\n",
        "     im = im.convert('L')\n",
        "     im=im.resize((256,256))\n",
        "     im=np.array(im)\n",
        "     pixel_stego.append(im)\n",
        "\n",
        "\n",
        "\n",
        "   return pixel_cover,pixel_stego\n",
        "\n",
        "pixel_cover,pixel_stego=get_train_data(cover_final_path,stego_final_path)\n",
        "\n",
        "\n",
        "#Y=train_df[\"Label\"].values\n",
        "pixel_cover=np.array(pixel_cover)\n",
        "pixel_stego=np.array(pixel_stego)\n",
        "X=np.concatenate([pixel_cover,pixel_stego])\n",
        "print(X.shape)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7OYEfn4kVL8Y",
        "outputId": "75fe9bc9-e748-423d-c8de-f16f69f66a34"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 22500/22500 [03:52<00:00, 96.59it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45000, 256, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1UeMbsPh7BCC",
        "outputId": "daa49b44-8de1-484d-fea3-6e1d6f343f18"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(45000, 256, 256)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_=X.reshape(45000,256,256)\n",
        "Y = (numpy.hstack(([0]*len(pixel_cover), [1]*len(pixel_stego))))"
      ],
      "metadata": {
        "id": "OK9oMXNiwwDa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 40,10,50\n",
        "\n",
        "Y = (numpy.hstack(([0]*len(pixel_cover), [1]*len(pixel_stego))))\n",
        "Y = np_utils.to_categorical(Y, 2)\n",
        "\n",
        "X_dat0, X_dat1, y_dat0, y_dat1 = train_test_split(X,Y, test_size=0.50, random_state=64)\n",
        "X = np.concatenate([X_dat0,X_dat1],axis=0)\n",
        "Y = np.concatenate([y_dat0,y_dat1],axis=0)\n",
        "\n",
        "X_train = np.concatenate([X[0:9000],X[22500:31500]],axis=0)\n",
        "X_valid = np.concatenate([X[9000:11250],X[31500:33750]],axis=0)\n",
        "X_test  = np.concatenate([X[11250:22500],X[33750:45000]],axis=0)\n",
        "y_train = np.concatenate([Y[0:9000],Y[22500:31500]],axis=0)\n",
        "y_valid = np.concatenate([Y[9000:11250],Y[31500:33750]],axis=0)\n",
        "y_test  = np.concatenate([Y[11250:22500],Y[33750:45000]],axis=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8mOzlbZqIZW",
        "outputId": "d3a4ec95-19f9-4b65-b339-b79aa3d0b211"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(18000, 256, 256)\n",
            "(18000, 2)\n",
            "(4500, 256, 256)\n",
            "(4500, 2)\n",
            "(22500, 256, 256)\n",
            "(22500, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## 40,10,50\n",
        "\n",
        "X_test  = np.concatenate([X[0:11250],X[22500:33750]],axis=0)\n",
        "\n",
        "y_test  = np.concatenate([Y[0:11250],Y[22500:33750]],axis=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "wVR2vuU7N0MC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(stego_final_path[15000])\n",
        "im=Image.open(stego_final_path[15000])\n",
        "im=im.convert('L')\n",
        "#im.size\n",
        "im.resize((256,256))"
      ],
      "metadata": {
        "id": "PBDQWyAFkm3I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(\n",
        "    X_train, y_train, test_size=0.20, random_state=2020)\n",
        "\n"
      ],
      "metadata": {
        "id": "vtxe-4KWPKb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "kvKIHnhgh4V_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##BOSS+BOW JPEG"
      ],
      "metadata": {
        "id": "piLNrWZep5f4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "##This dataset has not been used in the paper\n",
        "\n",
        "pathc = '/content/drive/MyDrive/archive'\n",
        "paths = '/content/drive/MyDrive/archive'\n",
        "\n",
        "Xc_ = pd.read_csv(pathc+'/gfr_cover.csv').values ##COVER IMAGES\n",
        "Xs_ = pd.read_csv(paths+'/juniward_gfr_stego_04.csv').values ##STEGO IMAGES\n",
        "#Xc_ = Xc_.to_numpy()\n",
        "#Xs_ = Xs_.to_numpy()\n",
        "\n",
        "#Xc_ = Xc_[:, 1:].reshape(Xc_.shape[0],1,17000,-1).astype( 'float32' )\n",
        "#Xc_ = Xc_ / 255.0\n",
        "\n",
        "#Xs_ = Xs_[:, 1:].reshape(Xs_.shape[0],1,100, 170).astype( 'float32' )\n",
        "#Xs_ = Xs_ / 255.0\n",
        "\n",
        "\n",
        "X_  = (numpy.vstack((Xc_, Xs_)))\n",
        "Xt_ = (numpy.hstack(([0]*len(Xc_), [1]*len(Xs_))))\n",
        "#\n",
        "Xt_ = np_utils.to_categorical(Xt_, 2)\n",
        "#\n",
        "X_  = np.rollaxis(X_,1,2)  #channel axis shifted to last axis\n",
        "\n",
        "print(\"Total image data and labels\",X_.shape,Xt_.shape)\n",
        "\n",
        "X_train = np.concatenate([X_[0:4000],X_[10000:14000]],axis=0)\n",
        "X_valid = np.concatenate([X_[4000:5000],X_[14000:15000]],axis=0)\n",
        "X_test  = np.concatenate([X_[5000:10000],X_[15000:20000]],axis=0)\n",
        "y_train = np.concatenate([Xt_[0:4000],Xt_[10000:14000]],axis=0)\n",
        "y_valid = np.concatenate([Xt_[4000:5000],Xt_[14000:15000]],axis=0)\n",
        "y_test  = np.concatenate([Xt_[5000:10000],Xt_[15000:20000]],axis=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Controled randomized data for training\n",
        "X_dat0, X_dat1, y_dat0, y_dat1 = train_test_split(X_train, y_train, test_size=0.50،random_state=64)\n",
        "X_train = np.concatenate([X_dat0,X_dat1],axis=0)\n",
        "y_train = np.concatenate([y_dat0,y_dat1],axis=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dIyg5vArp9lV",
        "outputId": "13e3e6dc-cc53-413b-8624-0299ce28ff75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total image data and labels (19998, 17000) (19998, 2)\n",
            "(8000, 17000)\n",
            "(8000, 2)\n",
            "(2000, 17000)\n",
            "(2000, 2)\n",
            "(9998, 17000)\n",
            "(9998, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_  = (numpy.vstack((Xc_, Xs_)))\n",
        "Xt_ = (numpy.hstack(([0]*len(Xc_), [1]*len(Xs_))))\n",
        "#\n",
        "Xt_ = np_utils.to_categorical(Xt_, 2)\n",
        "#\n",
        "X_  = np.rollaxis(X_,1,2)  #channel axis shifted to last axis\n",
        "\n",
        "print(\"Total image data and labels\",X_.shape,Xt_.shape)\n",
        "\n",
        "X_train = np.concatenate([X_[0:4000],X_[10000:14000]],axis=0)\n",
        "X_valid = np.concatenate([X_[4000:5000],X_[14000:15000]],axis=0)\n",
        "X_test  = np.concatenate([X_[5000:10000],X_[15000:20000]],axis=0)\n",
        "y_train = np.concatenate([Xt_[0:4000],Xt_[10000:14000]],axis=0)\n",
        "y_valid = np.concatenate([Xt_[4000:5000],Xt_[14000:15000]],axis=0)\n",
        "y_test  = np.concatenate([Xt_[5000:10000],Xt_[15000:20000]],axis=0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#Controled randomized data for training\n",
        "X_dat0, X_dat1, y_dat0, y_dat1 = train_test_split(X_train, y_train, test_size=0.50)\n",
        "X_train = np.concatenate([X_dat0,X_dat1],axis=0)\n",
        "y_train = np.concatenate([y_dat0,y_dat1],axis=0)\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PFJ0DxZ5_m_N",
        "outputId": "08c66c33-9b6e-4806-85d6-2b9253b8f0e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total image data and labels (19998, 17000) (19998, 2)\n",
            "(8000, 17000)\n",
            "(8000, 2)\n",
            "(2000, 17000)\n",
            "(2000, 2)\n",
            "(9998, 17000)\n",
            "(9998, 2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cover= pd.read_csv('/content/drive/MyDrive/archive/dctr_cover.csv',header=None)\n",
        "stego =pd.read_csv('/content/drive/MyDrive/archive/juniward_dctr_stego_04.csv', header= None)\n",
        "\n",
        "Xc_= cover.to_numpy\n",
        "Xs_= stego.to_numpy\n",
        "\n",
        "X_  = (numpy.vstack((Xc_, Xs_)))\n",
        "Xt_ = (numpy.hstack(([0]*len(Xc_), [1]*len(Xs_))))\n",
        "Xt_ = np_utils.to_categorical(Xt_, 2)\n",
        "X_  = np.rollaxis(X_,1,4)  #channel axis shifted to last axis\n",
        "\n",
        "print(\"Total image data and labels\",X_.shape,Xt_.shape)\n"
      ],
      "metadata": {
        "id": "V_kgl36BtfHr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bb6ucZGAonHM"
      },
      "source": [
        "## BOSSbase 1.01+BOWS2, PAYLOAD = 0.4bpp"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U9Mp2HhEonHM"
      },
      "source": [
        "## Training image pairs(4000), Validation image pairs(1000), and Test image pairs(5000)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4YhKVzPsHT46",
        "outputId": "347be452-869c-4799-c701-0f2bfddbd51d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8000, 256, 256, 1)\n",
            "(8000, 2)\n",
            "(2000, 256, 256, 1)\n",
            "(2000, 2)\n",
            "(10000, 256, 256, 1)\n",
            "(10000, 2)\n"
          ]
        }
      ],
      "source": [
        "\n",
        "PATH04 = '/content/drive/MyDrive/Steganalysis/DATABASES/Strategy/COVER_STEGO_02_04bpp_size256/payload_04bpp'\n",
        "#PATH02 = '/content/drive/MyDrive/Steganalysis/DATABASES/Strategy/COVER_STEGO_02_04bpp_size256/payload_02bpp'\n",
        "#Dataset\n",
        "\n",
        "PATH04_WOW1 = '/1WOW/BOSSbase1_01_train4000_valid1000_test5000/NPY/'\n",
        "#PATH04_SUN3 = \"/3S-UNIWARD/BOSSbase1_01_train4000_valid1000_test5000/NPY/\"\n",
        "#PATH04_WOW1= \"/1WOW/BOSSbase1_01-BOWS2_train14000_valid1000_test5000/NPY/\"\n",
        "#PATH04_SUN3=\"/3S-UNIWARD/BOSSbase1_01-BOWS2_train14000_valid1000_test5000/NPY/\"\n",
        "#Train\n",
        "X_train = np.load(PATH04+PATH04_WOW1+'X_train.npy')\n",
        "y_train = np.load(PATH04+PATH04_WOW1+'y_train.npy')\n",
        "#Valid\n",
        "X_valid = np.load(PATH04+PATH04_WOW1+'X_valid.npy')\n",
        "y_valid = np.load(PATH04+PATH04_WOW1+'y_valid.npy')\n",
        "#Test\n",
        "X_test = np.load(PATH04+PATH04_WOW1+'X_test.npy')\n",
        "y_test = np.load(PATH04+PATH04_WOW1+'y_test.npy')\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n=256\n",
        "#n=64\n",
        "def load_images(path_pattern):\n",
        "    files=glob.glob(path_pattern)\n",
        "    X=[]\n",
        "    for f in sorted(files):\n",
        "        I = cv2.imread(f, cv2.IMREAD_GRAYSCALE)\n",
        "        patches = view_as_blocks(I, (n, n))\n",
        "        for i in range(patches.shape[0]):\n",
        "            for j in range(patches.shape[1]):\n",
        "                X.append( [ patches[i,j] ] )\n",
        "    X=numpy.array(X)\n",
        "    return X\n",
        "    print('x',X)\n",
        "\n",
        "pathc = '/content/drive/MyDrive/Steganalysis/DATABASES/GBRAS-Net/BOSSbase-1.01'\n",
        "paths = '/content/drive/MyDrive/Steganalysis/DATABASES/GBRAS-Net/BOSSbase-1.01/WOW/0.4bpp'\n",
        "\n",
        "Xc_ = load_images(pathc+'/cover/*.pgm') ##COVER IMAGES\n",
        "Xs_ = load_images(paths+'/stego/*.pgm') ##STEGO IMAGES\n",
        "X_  = (numpy.vstack((Xc_, Xs_)))\n",
        "Xt_ = (numpy.hstack(([0]*len(Xc_), [1]*len(Xs_))))\n",
        "Xt_ = np_utils.to_categorical(Xt_, 2)\n",
        "X_  = np.rollaxis(X_,1,4)  #channel axis shifted to last axis\n",
        "\n",
        "print(\"Total image data and labels\",X_.shape,Xt_.shape)\n",
        "\n",
        "X_train = np.concatenate([X_[0:4000],X_[10000:14000]],axis=0)\n",
        "X_valid = np.concatenate([X_[4000:5000],X_[14000:15000]],axis=0)\n",
        "X_test  = np.concatenate([X_[5000:10000],X_[15000:20000]],axis=0)\n",
        "y_train = np.concatenate([Xt_[0:4000],Xt_[10000:14000]],axis=0)\n",
        "y_valid = np.concatenate([Xt_[4000:5000],Xt_[14000:15000]],axis=0)\n",
        "y_test  = np.concatenate([Xt_[5000:10000],Xt_[15000:20000]],axis=0)\n",
        "#Controled randomized data for training\n",
        "X_dat0, X_dat1, y_dat0, y_dat1 = train_test_split(X_train, y_train, test_size=0.50, random_state=64)\n",
        "X_train = np.concatenate([X_dat0,X_dat1],axis=0)\n",
        "y_train = np.concatenate([y_dat0,y_dat1],axis=0)\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(X_valid.shape)\n",
        "print(y_valid.shape)\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "metadata": {
        "id": "ugnS9Oh7b2Xo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pp-qWDOonHO"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PF9gnSMEonHO"
      },
      "outputs": [],
      "source": [
        "path_model = \"/content/drive/MyDrive/Colab Notebooks/Steganalysis/logs1/\"\n",
        "path_img_base = \"/content/drive/MyDrive/Colab Notebooks/Steganalysis/images1\"\n",
        "\n",
        "\n",
        "base_name=\"WOW_\"\n",
        "m_name=\"yedroudj_Net_LSTM_\"\n",
        "#m_name=\"time\"\n",
        "name= \"Model_\"+m_name+\"_\"+base_name\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "trainTPU(path_model=path_model, epochs=150, model_Name = name)"
      ],
      "metadata": {
        "id": "SsA6duk1OdAT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHwvETPMonHP"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5_e1GfMonHP"
      },
      "outputs": [],
      "source": [
        "Final_Results_Train(path_model+\"/\"+name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oyvYOrvaonHO"
      },
      "source": [
        "## Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zHuJ6_HbonHP"
      },
      "outputs": [],
      "source": [
        "Final_Results_Valid(path_model+\"/\"+name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cK2MjsIConHO"
      },
      "source": [
        "## Test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7rS3rDOzonHO"
      },
      "outputs": [],
      "source": [
        "Final_Results_Test(path_model+\"/\"+name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JZYNZpPBonHP"
      },
      "source": [
        "## Training, validation and testing graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gPZ0xZshonHP"
      },
      "outputs": [],
      "source": [
        "graphics(AccTest, AccTrain, AccValid, LossTest, LossTrain, LossValid, name, path_img_base)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model= Zhu_Net()\n",
        "model.load_weights(\"/content/drive/MyDrive/Colab Notebooks/Steganalysis/logs/Model_Ye_Net_LSTM2_TPU_04WOW1_Boss/0119.hdf5\") #path best model"
      ],
      "metadata": {
        "id": "MuW9LzKT6Tii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mj6u2MwkonHP"
      },
      "source": [
        "## Top"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V4To0ll-onHP"
      },
      "outputs": [],
      "source": [
        "top_models(AccTest,AccTrain,AccValid)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9D9HG_44onHP"
      },
      "source": [
        "Note: If you want to train the algorithm with S-UNIWARD 0.4 bpp, change \"PATH04_WOW1\" and  \"base_name\"."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HXP6pvUR9wTw"
      },
      "source": [
        "## **ROC Plot**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 460
        },
        "id": "nX69xYAO9tG5",
        "outputId": "510bf10f-8a9c-4fc6-87d5-6649671cebde"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Ye-net model 2 generated\n"
          ]
        },
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 504x504 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "model= Ye_Net()\n",
        "model.load_weights(\"/content/drive/MyDrive/Colab Notebooks/Steganalysis/logs/Model_Ye_Net_LSTM2_TPU_04WOW1_Boss/0119.hdf5\") #path best model\n",
        "predictions= model.predict(X_test,verbose=0)\n",
        "labels = [\"Cover\",\"Stego\"]\n",
        "model_name=\"ye_Net_WOW04_LSTM- \"\n",
        "curve1,labels1=get_curve(y_test, predictions, labels,model_name)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "collapsed_sections": [
        "83r4FrFXonHD",
        "jGYyQp73onHE",
        "FoopVm6YplcX",
        "5IVvyv0NprUq",
        "ukNFndcRpvgM",
        "F73TYdW0onHI",
        "ui4IMt5CGTOH",
        "piLNrWZep5f4"
      ],
      "machine_shape": "hm",
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Semillero",
      "language": "python",
      "name": "semillero"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}